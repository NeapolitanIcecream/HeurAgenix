# LLVM MIR Peephole Optimization Problem

This problem environment enables the HeurAgenix framework to automatically generate and evaluate peephole optimization patterns for LLVM's Machine IR (MIR). It works by dynamically compiling these patterns into a GlobalISel Combiner pass plugin and evaluating its impact on a given set of benchmarks.

## 1. Critical Prerequisites

Correctly setting up the LLVM toolchain is essential for this environment to function.

### 1.1. Build LLVM with Plugin Support

Your local LLVM installation **must** be built with plugin support enabled. If you see errors like `pass plugins are not supported in this build` during runtime, you need to recompile LLVM.

Use the following CMake configuration to build LLVM from the source:
```bash
# From your build directory
cmake -G Ninja ../llvm-project/llvm \
      -DLLVM_ENABLE_PROJECTS="clang" \
      -DBUILD_SHARED_LIBS=ON \
      -DLLVM_ENABLE_PLUGINS=ON
ninja
```

### 1.2. Required Tools

Ensure the following tools are installed and available in your system's `PATH`:
- `cmake` (version >= 3.13)
- `ninja`
- A C++ compiler compatible with your LLVM version (e.g., `clang++`)

The environment will automatically locate the necessary LLVM binaries (`llc`, `llvm-config`, etc.) by searching these locations in order:
1. The path specified in the `LLVM_HOME` or `LLVM_INSTALL_DIR` environment variables.
2. The directory returned by `llvm-config --bindir`.
3. The location of `llc` found in your system's `PATH`.

## 2. Configuration via Environment Variables

The behavior of the environment can be customized using the following environment variables:

| Variable                            | Description                                                                                              | Default Value                                  |
|-------------------------------------|----------------------------------------------------------------------------------------------------------|------------------------------------------------|
| `LLVM_TRIPLE`                       | The target architecture triple for compilation.                                                          | `x86_64`                                       |
| `LLVM_ISA_JSON`                     | (Optional) Path to a JSON file containing ISA metadata for richer problem state. See below for generation. | Not set                                        |
| `LLVM_MIR_PEEPHOLE_PLUGIN_CACHE`    | Overrides the default directory for caching compiled plugins.                                            | `/tmp/llvm_mir_peephole_plugins`               |
| `LLVM_MIR_PEEPHOLE_NINJA_JOBS`      | Controls the number of parallel jobs used by Ninja to build the plugin.                                  | System's CPU count                             |

### Generating ISA Metadata

To provide detailed Instruction Set Architecture (ISA) information to the LLM, you can generate a metadata file using `llvm-tblgen`. This is optional but recommended.

```bash
# Example for X86 architecture
# Replace $(LLVM_SRC_ROOT) with the path to your llvm-project source directory
llvm-tblgen --dump-json -gen-target-desc \
    $(LLVM_SRC_ROOT)/llvm/lib/Target/X86/X86.td > x86_isa.json

# Set the environment variable for the framework to use it
export LLVM_ISA_JSON=$PWD/x86_isa.json
```

## 3. Data Setup

The benchmark data for this problem consists of LLVM IR files (`.ll`). The framework expects these files to be organized in the standard data structure, for example:
```
output/
└── llvm_mir_peephole/
    └── data/
        ├── smoke_data/
        │   └── test1.ll
        └── test_data/
            └── benchmark1.ll
```

## 4. How It Works

This environment integrates with LLVM through a sophisticated process:
1.  **Dynamic Plugin Compilation**: Instead of interpreting patterns, the framework takes the TableGen `GICombineRule` definitions generated by the LLM and dynamically builds a shared library (`.so`, `.dylib`, or `.dll`) that acts as an `llc` pass plugin.
2.  **Performance Caching**:
    *   **Plugin Cache**: Compiled plugins are cached based on a hash of the patterns they contain. This avoids redundant compilations when the same set of patterns is evaluated repeatedly. To clear the cache, simply remove the cache directory.
    *   **Baseline Cache**: The instruction count of the original, un-optimized IR files is also cached to speed up the calculation of the reduction rate.
3.  **Parallel Evaluation**: To accelerate the evaluation process, the framework applies the generated plugin to the benchmark files in parallel using a thread pool.

## 5. Pattern Definition

A peephole optimization is defined by the `MIRPeepholePattern` class in `components.py`. The most important attribute is `td_rule`, which should contain a valid `GICombineRule` definition in TableGen syntax.

The framework automatically handles the necessary boilerplate, such as wrapping the rules in a `GICombinerRuleSet`. You only need to provide the rule definition itself. The `name` field of the pattern must match the name used in the `def` of the TableGen rule.

Example of a `td_rule`:
```tablegen
def MyRule_CombineAddZero : GICombineRule<
  (defs root:G_ADD, i32_0),
  (apply (defs root), (match-true))
>;
```

## 6. Running Tests
To verify the environment setup, run the specific test suite:
```bash
pytest tests/test_llvm_peephole.py
```

